{
    "preguntas": [
        {
            "id": 1,
            "pregunta": "¿Qué es el aprendizaje por analogía y cómo funciona?",
            "respuesta": "El aprendizaje por analogía es un paradigma que se basa en el uso de experiencias previas para solucionar problemas nuevos, bajo la suposición de que problemas semejantes tienen soluciones semejantes. Este tipo de razonamiento es típico en el aprendizaje humano y se basa en instancias previas para clasificar nuevas instancias."
        },
        {
            "id": 2,
            "pregunta": "¿Qué es el algoritmo k-NN y cuál es su objetivo principal?",
            "respuesta": "El algoritmo k-NN (k-Nearest Neighbour) clasifica nuevas instancias en función de las clases de sus k vecinos más cercanos en el espacio de atributos. Su objetivo principal es etiquetar las nuevas instancias con la clase más común entre sus k vecinos más cercanos, siendo útil tanto para problemas de clasificación como de regresión."
        },
        {
            "id": 3,
            "pregunta": "¿Cómo se calcula la distancia entre dos instancias en k-NN?",
            "respuesta": "La distancia entre dos instancias se puede calcular utilizando varias métricas como la distancia Euclidiana, la distancia Manhattan o la distancia de Minkowski, dependiendo de las características del espacio de atributos."
        },
        {
            "id": 4,
            "pregunta": "¿Qué se debe hacer si los atributos tienen distintos rangos en k-NN?",
            "respuesta": "Si los atributos tienen diferentes rangos, es necesario normalizarlos, ya que de no hacerlo, aquellos atributos con un rango mayor tendrán más peso en el cálculo de la distancia, lo cual puede distorsionar los resultados."
        },
        {
            "id": 5,
            "pregunta": "¿Qué es la distancia de Hamming y cuándo se utiliza?",
            "respuesta": "La distancia de Hamming se utiliza para comparar instancias con variables categóricas o datos binarios, donde el valor de la distancia es 0 si los atributos coinciden y 1 si son diferentes."
        },
        {
            "id": 6,
            "pregunta": "¿Cómo se selecciona el valor de k en el algoritmo k-NN?",
            "respuesta": "El valor de k se selecciona generalmente mediante prueba y error, utilizando valores impares (3, 5, 7, etc.) para evitar empates en el caso de tener solo dos clases. En problemas con más de dos clases, se pueden implementar reglas heurísticas para romper los empates."
        },
        {
            "id": 7,
            "pregunta": "¿Qué variantes de k-NN se mencionan en el documento?",
            "respuesta": "Se mencionan varias variantes de k-NN como k-NN con rechazo, k-NN con ponderación de los vecinos, k-NN con distancia mínima y k-NN con ponderación de variables."
        },
        {
            "id": 8,
            "pregunta": "¿En qué consiste el método k-NN ponderado por distancia?",
            "respuesta": "En el método k-NN ponderado por distancia, cada vecino contribuye al valor de la función objetivo en función de la distancia que lo separa de la instancia a clasificar. Los vecinos más cercanos tienen mayor peso en la clasificación."
        },
        {
            "id": 9,
            "pregunta": "¿Qué es la 'maldición de la dimensionalidad' en el contexto de k-NN?",
            "respuesta": "La 'maldición de la dimensionalidad' se refiere al problema que surge cuando se incrementa el número de atributos en un conjunto de datos. Cuantos más atributos hay, más instancias se necesitan y es más probable que aparezcan atributos irrelevantes, lo que afecta negativamente el rendimiento del algoritmo k-NN."
        },
        {
            "id": 10,
            "pregunta": "¿Qué técnicas se mencionan para optimizar k-NN cuando el dataset es muy grande?",
            "respuesta": "Algunas técnicas mencionadas para optimizar k-NN en datasets grandes incluyen la indexación mediante árboles kd, el clustering y la selección o reemplazo de instancias utilizando métodos como Hart Condensation o Wilson Edition."
        },
        {
            "id": 11,
            "pregunta": "¿Qué es el razonamiento basado en casos (CBR) y cómo funciona?",
            "respuesta": "El razonamiento basado en casos (CBR) es una técnica de inteligencia artificial que resuelve nuevos problemas utilizando experiencias previas similares. Busca en una base de casos problemas ya resueltos y adapta sus soluciones para resolver el nuevo problema."
        },
        {
            "id": 12,
            "pregunta": "¿Qué actividades están involucradas en la metodología CBR?",
            "respuesta": "Las actividades principales de la metodología CBR son recuperar los casos más similares, reusar la solución de esos casos, revisar si la solución es adecuada y retener el nuevo caso resuelto en la base de casos."
        },
        {
            "id": 13,
            "pregunta": "¿Cuáles son las ventajas y desventajas de los modelos locales híbridos en k-NN?",
            "respuesta": "Las ventajas de los modelos locales híbridos incluyen una mejor adaptación en espacios complejos, mientras que las desventajas incluyen mayores necesidades computacionales debido al cálculo de vecinos más cercanos y la creación de un modelo para cada predicción."
        },
        {
            "id": 14,
            "pregunta": "¿Cómo funcionan los modelos locales híbridos en problemas de clasificación?",
            "respuesta": "En problemas de clasificación, en lugar de hacer una votación entre los vecinos más cercanos, se entrena un clasificador de baja complejidad, como un SVM lineal, con esos vecinos, bajo la suposición de que los datos son linealmente separables localmente."
        },
        {
            "id": 15,
            "pregunta": "¿Qué es la transinducción en el contexto de k-NN?",
            "respuesta": "La transinducción en k-NN se refiere a que los pasos de inducción (entrenamiento) y deducción (prueba) están combinados. No existe un modelo global, sino que se realizan aproximaciones locales cada vez que se quiere clasificar una nueva instancia."
        }
    ]
}
